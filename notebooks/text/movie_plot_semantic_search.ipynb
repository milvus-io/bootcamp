{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search with Movie Plots\n",
    "\n",
    "How do you find movies based on what they're about? Semantic search.\n",
    "\n",
    "We can use movie plots and phrases to search through a movie database and pick movies based on which movies are the most similar to our search phrase. In this example, we create a way to do semantic search on movies in the Wikipedia-Movie-Plots Dataset found on [Kaggle](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots). We put together a system to semantically search movie plots using a vector database and the sentence-transformers library. For this example, we use [Milvus Lite](https://milvus.io/docs/milvus_lite.md) to run our vector database locally. \n",
    "\n",
    "We begin by installing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pymilvus==2.2.5 sentence-transformers gdown milvus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download the data and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "url = 'https://drive.google.com/uc?id=11ISS45aO2ubNCGaC3Lvd3D7NT8Y7MeO8'\n",
    "output = './movies.zip'\n",
    "gdown.download(url, output)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"./movies.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./movies\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to establish some constants for our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'movies_db'  # Collection name\n",
    "DIMENSION = 384  # Embeddings size\n",
    "\n",
    "# Inference Arguments\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Search Arguments\n",
    "TOP_K = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our constants established for consistency, we spin up an instance of Milvus to locally run a vector database, making sure that we're not duplicating any existing collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from milvus import default_server\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "# (OPTIONAL) Set if you want store all related data to specific location\n",
    "# Default location:\n",
    "#   %APPDATA%/milvus-io/milvus-server on windows\n",
    "#   ~/.milvus-io/milvus-server on linux\n",
    "# default_server.set_base_dir('milvus_data')\n",
    "\n",
    "# (OPTIONAL) if you want cleanup previous data\n",
    "# default_server.cleanup()\n",
    "\n",
    "# Start your milvus server\n",
    "default_server.start()\n",
    "\n",
    "# Now you could connect with localhost and the given port\n",
    "# Port is defined by default_server.listen_port\n",
    "connections.connect(host='127.0.0.1', port=default_server.listen_port)\n",
    "\n",
    "# Check if the server is ready.\n",
    "print(utility.get_server_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an instance of a vector database spun up. Let's define our schema and create a collection.\n",
    "\n",
    "For these movies, each object in the database needs three components: an ID, a title, and the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "\n",
    "\n",
    "# Create collection which includes the id, title, and embedding.\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=200),  # VARCHARS need a maximum length, so for this example they are set to 200 characters\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields)\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the vector index. For this example, we use an IVF index on an L2 distance metric with 128 vector indices just like we do in the\n",
    "[reverse image search example notebook](../vision/reverse_painting_search.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "collection.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our local vector database set up, we can dive into creating vectors out of movie plots and putting them into a vector space.\n",
    "\n",
    "For this example, we use the [MiniLM L6 v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "transformer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our embeddings extractor loaded, we need the movie titles and plots to embed. Taking a look at the data from the [Kaggle page](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots), we see that the data contains eight columns. We are only interested in the title (column 2) and the plot (column 8) so our `csv_load` function extracts just those.\n",
    "\n",
    "The second function we write in the block below takes a tuple, the `(title, plot)` tuple we create with `csv_load`, and turns that into an object we store in our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the movie titles\n",
    "def csv_load(file):\n",
    "    with open(file, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            if '' in (row[1], row[7]):\n",
    "                continue\n",
    "            yield (row[1], row[7])\n",
    "\n",
    "\n",
    "# Extract embeding from text using SentenceTransformer\n",
    "def embed_insert(data: tuple):\n",
    "    embeds = transformer.encode(data[1]) \n",
    "    ins = [\n",
    "            data[0],\n",
    "            [x for x in embeds]\n",
    "    ]\n",
    "    collection.insert(ins)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector database is set up, we have a model for the embeddings, and we have the functions we need to get embeddings from our text. The next step to be able to semantically search movie plots is to get the embeddings and populate the database.\n",
    "\n",
    "*This step takes over 12 minutes on a 16GB RAM M1 Mac, we are processing 35000 movies!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = [[],[]]\n",
    "\n",
    "for title, plot in csv_load('./movies/plots.csv'):\n",
    "    data_batch[0].append(title)\n",
    "    data_batch[1].append(plot)\n",
    "    if len(data_batch[0]) % BATCH_SIZE == 0:\n",
    "        embed_insert(data_batch)\n",
    "        data_batch = [[],[]]\n",
    "\n",
    "# Embed and insert the remainder\n",
    "if len(data_batch[0]) != 0:\n",
    "    embed_insert(data_batch)\n",
    "\n",
    "# Call a flush to index any unsealed segments.\n",
    "collection.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run a semantic search on our movies and their plots. \n",
    "\n",
    "We start by coming up with some search terms and embedding them using the same transformer we used to get the embeddings for the movie plots before. Then, we search the collection for these embeddings and output the titles for the top 3 results.\n",
    "\n",
    "For this example, we search for two movies. The example blurbs I've come up with are \"We do not talk about fight club.\" and \"Boxing with a Russian.\" Ideally we are looking for a return value that includes Fight Club for the first term and Rocky IV for the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Search for titles whose plots closely match these phrases.\n",
    "search_terms = ['We do not talk about fight club.', 'Boxing with a Russian.']\n",
    "\n",
    "# Search the database based on input text\n",
    "def embed_search(data):\n",
    "    embeds = transformer.encode(data) \n",
    "    return [x for x in embeds]\n",
    "\n",
    "search_data = embed_search(search_terms)\n",
    "\n",
    "start = time.time()\n",
    "res = collection.search(\n",
    "    data=search_data,  # Embeded search value\n",
    "    anns_field=\"embedding\",  # Search across embeddings\n",
    "    param={\"metric_type\": \"L2\",\n",
    "            \"params\": {\"nprobe\": 10}},\n",
    "    limit = TOP_K,  # Limit to top_k results per search\n",
    "    output_fields=['title']  # Include title field in result\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "for hits_i, hits in enumerate(res):\n",
    "    print('Title:', search_terms[hits_i])\n",
    "    print('Search Time:', end-start)\n",
    "    print('Results:')\n",
    "    for hit in hits:\n",
    "        print( hit.entity.get('title'), '----', hit.distance)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "default_server.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
