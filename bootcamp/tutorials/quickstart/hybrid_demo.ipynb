{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/hybrid_serach_with_milvus.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Semantic Search with Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate the use of Milvus Hybrid Search with the BGE-M3 model to enhance search result relevance.\n",
    "\n",
    "Milvus Hybrid Search integrates Dense, Sparse, and Hybrid retrieval methods:\n",
    "\n",
    "- Dense Retrieval: Utilizes semantic context to understand the meaning behind queries.\n",
    "- Sparse Retrieval: Emphasizes keyword matching to find results based on specific terms.\n",
    "- Hybrid Retrieval: Combines both Dense and Sparse approaches, capturing the full context and specific keywords for comprehensive search results.\n",
    "\n",
    "By integrating these methods, the Milvus Hybrid Search balances semantic and lexical similarities, improving the overall relevance of search outcomes. This notebook will walk through the process of setting up and using these retrieval strategies, highlighting their effectiveness in various search scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pymilvus \"pymilvus[model]\" milvus-lite pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Quora Duplicate Questions dataset and place it in the same directory.\n",
    "\n",
    "Credit for the dataset: [First Quora Dataset Release: Question Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download the dataset\n",
    "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data\n",
    "\n",
    "We will load the dataset and prepare a small corpus for search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whose questions do you follow the most on a regular basis?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"quora_duplicate_questions.tsv\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "questions = set()\n",
    "for _, row in df.iterrows():\n",
    "    obj = row.to_dict()\n",
    "    questions.add(obj[\"question1\"][:512])\n",
    "    questions.add(obj[\"question2\"][:512])\n",
    "    if len(questions) > 10000:\n",
    "        break\n",
    "\n",
    "docs = list(questions)\n",
    "\n",
    "# example question\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Random Embeddings (Optional)\n",
    "\n",
    "If you do not have the BGE-M3 model, you can generate random embeddings for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def random_embedding(texts):\n",
    "    rng = np.random.default_rng()\n",
    "    return {\n",
    "        \"dense\": np.random.rand(len(texts), 768),\n",
    "        \"sparse\": [\n",
    "            {\n",
    "                d: rng.random()\n",
    "                for d in random.sample(range(1000), random.randint(20, 30))\n",
    "            }\n",
    "            for _ in texts\n",
    "        ],\n",
    "    }\n",
    "\n",
    "dense_dim = 768\n",
    "ef = random_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BGE-M3 Model for Embeddings\n",
    "\n",
    "The BGE-M3 model can embed texts as dense and sparse vectors. Ensure you have installed the `model` module in pymilvus.\n",
    "\n",
    "To install it, simply run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"pymilvus[model]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 302473.85it/s]\n",
      "Inference Embeddings: 100%|██████████| 626/626 [04:43<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from milvus_model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")\n",
    "dense_dim = ef.dim[\"dense\"]\n",
    "\n",
    "# Generate embeddings using BGE-M3 model\n",
    "docs_embeddings = ef(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Milvus Collection and Index\n",
    "\n",
    "We will now set up the Milvus collection and create indices for the vector fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    connections,\n",
    ")\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(\"default\", uri=\"milvus.db\")\n",
    "\n",
    "# Specify the data schema for the new Collection\n",
    "fields = [\n",
    "    # Use auto generated id as primary key\n",
    "    FieldSchema(\n",
    "        name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n",
    "    ),\n",
    "    # Store the original text to retrieve based on semantically distance\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512),\n",
    "    # Milvus now supports both sparse and dense vectors,\n",
    "    # we can store each in a separate field to conduct hybrid search on both vectors\n",
    "    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "]\n",
    "schema = CollectionSchema(fields, \"\")\n",
    "col_name = \"hybrid_demo\"\n",
    "col = Collection(col_name, schema, consistency_level=\"Strong\")\n",
    "\n",
    "# Create indices for the vector fields\n",
    "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "col.create_index(\"sparse_vector\", sparse_index)\n",
    "dense_index = {\"index_type\": \"FLAT\", \"metric_type\": \"IP\"}\n",
    "col.create_index(\"dense_vector\", dense_index)\n",
    "col.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Data into Milvus Collection\n",
    "Insert the text and sparse/dense vector representations into the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert documents and their embeddings into the collection\n",
    "entities = [docs, docs_embeddings[\"sparse\"], docs_embeddings[\"dense\"]]\n",
    "for i in range(0, len(docs), 50):\n",
    "    batched_entities = [\n",
    "        docs[i : i + 50],\n",
    "        docs_embeddings[\"sparse\"][i : i + 50],\n",
    "        docs_embeddings[\"dense\"][i : i + 50],\n",
    "    ]\n",
    "    col.insert(batched_entities)\n",
    "col.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Collection Initialization\n",
    "Initialize the BGE-M3 model and Milvus collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 319363.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "def get_model():\n",
    "    ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")\n",
    "    return ef\n",
    "\n",
    "# Initialize the collection\n",
    "def get_collection():\n",
    "    col_name = \"hybrid_demo\"\n",
    "    connections.connect(\"default\", uri=\"milvus.db\")\n",
    "    col = Collection(col_name)\n",
    "    return col\n",
    "\n",
    "# Fetch the model and collection\n",
    "ef = get_model()\n",
    "col = get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Search\n",
    "\n",
    "Define helper functions for hybrid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_from_source(source, query):\n",
    "    return [f\"{source} Result {i+1} for {query}\" for i in range(5)]\n",
    "\n",
    "def get_tokenizer():\n",
    "    tokenizer = ef.model.tokenizer\n",
    "    return tokenizer\n",
    "\n",
    "def doc_text_formatting(query, docs):\n",
    "    tokenizer = get_tokenizer()\n",
    "    query_tokens_ids = tokenizer.encode(query, return_offsets_mapping=True)\n",
    "    query_tokens = tokenizer.convert_ids_to_tokens(query_tokens_ids)\n",
    "    formatted_texts = []\n",
    "\n",
    "    for doc in docs:\n",
    "        ldx = 0\n",
    "        landmarks = []\n",
    "        encoding = tokenizer.encode_plus(doc, return_offsets_mapping=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])[1:-1]\n",
    "        offsets = encoding[\"offset_mapping\"][1:-1]\n",
    "        for token, (start, end) in zip(tokens, offsets):\n",
    "            if token in query_tokens:\n",
    "                if len(landmarks) != 0 and start == landmarks[-1]:\n",
    "                    landmarks[-1] = end\n",
    "                else:\n",
    "                    landmarks.append(start)\n",
    "                    landmarks.append(end)\n",
    "        close = False\n",
    "        formatted_text = \"\"\n",
    "        for i, c in enumerate(doc):\n",
    "            if ldx == len(landmarks):\n",
    "                pass\n",
    "            elif i == landmarks[ldx]:\n",
    "                if close is True:\n",
    "                    formatted_text += \"]\"\n",
    "                else:\n",
    "                    formatted_text += \"[\"\n",
    "                close = not close\n",
    "                ldx = ldx + 1\n",
    "            formatted_text += c\n",
    "        if close is True:\n",
    "            formatted_text += \"]\"\n",
    "        formatted_texts.append(formatted_text)\n",
    "    return formatted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    AnnSearchRequest,\n",
    "    WeightedRanker,\n",
    ")\n",
    "\n",
    "def hybrid_search(query_embeddings, sparse_weight=1.0, dense_weight=1.0):\n",
    "    col = get_collection()\n",
    "    sparse_search_params = {\"metric_type\": \"IP\"}\n",
    "    sparse_req = AnnSearchRequest(\n",
    "        query_embeddings[\"sparse\"], \"sparse_vector\", sparse_search_params, limit=10\n",
    "    )\n",
    "    dense_search_params = {\"metric_type\": \"IP\"}\n",
    "    dense_req = AnnSearchRequest(\n",
    "        query_embeddings[\"dense\"], \"dense_vector\", dense_search_params, limit=10\n",
    "    )\n",
    "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "    res = col.hybrid_search(\n",
    "        [sparse_req, dense_req], rerank=rerank, limit=10, output_fields=[\"text\"]\n",
    "    )\n",
    "    if len(res):\n",
    "        return [hit.fields[\"text\"] for hit in res[0]]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Your Search Query\n",
    "\n",
    "Enter your search query and run the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who started AI research?\n",
      "{'dense': [array([-0.03658685, -0.01750261, -0.01536112, ..., -0.02266536,\n",
      "        0.01365146,  0.00908284], dtype=float32)], 'sparse': <1x250002 sparse array of type '<class 'numpy.float32'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>}\n"
     ]
    }
   ],
   "source": [
    "# Enter your search query\n",
    "query = input(\"Enter your search query: \")\n",
    "print(query)\n",
    "\n",
    "# Generate embeddings for the query\n",
    "query_embeddings = ef([query])\n",
    "print(query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Search Results\n",
    "\n",
    "Perform the search and display the results for Dense, Sparse, and Hybrid methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Search Results:\n",
      "What's the best way to start learning robotics?\n",
      "When in history did we start giving people names?\n",
      "Why did humans come into existence?\n",
      "Who invented thermometer?\n",
      "Should a machine learning beginner go straight for deep learning?\n",
      "How do I start learning or strengthen my knowledge of data structures and algorithms?\n",
      "How can undergraduate help with machine learning research?\n",
      "Why do so many people believe that the IQ test determines your intelligence?\n",
      "Why is the term \"research\" used instead of scientific investigation?\n",
      "Do humans fear artificial intelligence because it has no soul?\n",
      "What is research objective?\n",
      "What topic should I research for my EPQ project?\n",
      "What is the best way to do an MUN research?\n",
      "What advice will you give to an IIT graduate in Mechanical/Civil Engineering, who strongly wants to pursue a research career in computer science/mathematics, and has completed the basic courses of CS in coursera?\n",
      "How do I research for MUN?\n",
      "How could neutrinos be used for scientific research?\n",
      "What are the top research fields in electrical engineering?\n",
      "What is subjectivity and objectivity in research?\n",
      "How do I get help for research paper?\n",
      "\n",
      "Sparse Search Results:\n",
      "What is[ research] objective[?]\n",
      "How do I[ research] for MUN[?]\n",
      "What is the best way to do an MUN[ research?]\n",
      "What is subjectivity and objectivity in[ research?]\n",
      "What topic should I[ research] for my EPQ project[?]\n",
      "How could neutrinos be used for scientific[ research?]\n",
      "How do I get help for[ research] paper[?]\n",
      "What advice will you give to an IIT graduate in Mechanical/Civil Engineering, who strongly wants to pursue a[ research] career in computer science/mathematics, and has completed the basic courses of CS in coursera[?]\n",
      "What are the top[ research] fields in electrical engineering[?]\n",
      "How can undergraduate help with machine learning[ research?]\n",
      "Why did humans come into existence[?]\n",
      "Why do so many people believe that the IQ test determines your intelligence[?]\n",
      "[Who] invented thermometer[?]\n",
      "How do I start learning or strengthen my knowledge of data structures and algorithms[?]\n",
      "Should a machine learning beginner go straight for deep learning[?]\n",
      "What's the best way to start learning robotics[?]\n",
      "Why is the term \"research\" used instead of scientific investigation[?]\n",
      "Do humans fear artificial intelligence because it has no soul[?]\n",
      "When in history did we start giving people names[?]\n",
      "\n",
      "Hybrid Search Results:\n",
      "How can undergraduate help with machine learning[ research?]\n",
      "What's the best way to start learning robotics[?]\n",
      "When in history did we start giving people names[?]\n",
      "Why did humans come into existence[?]\n",
      "[Who] invented thermometer[?]\n",
      "Should a machine learning beginner go straight for deep learning[?]\n",
      "How do I start learning or strengthen my knowledge of data structures and algorithms[?]\n",
      "Why do so many people believe that the IQ test determines your intelligence[?]\n",
      "Why is the term \"research\" used instead of scientific investigation[?]\n",
      "Do humans fear artificial intelligence because it has no soul[?]\n",
      "What is[ research] objective[?]\n",
      "How do I[ research] for MUN[?]\n",
      "What is the best way to do an MUN[ research?]\n",
      "What is subjectivity and objectivity in[ research?]\n",
      "What topic should I[ research] for my EPQ project[?]\n",
      "How could neutrinos be used for scientific[ research?]\n",
      "How do I get help for[ research] paper[?]\n",
      "What advice will you give to an IIT graduate in Mechanical/Civil Engineering, who strongly wants to pursue a[ research] career in computer science/mathematics, and has completed the basic courses of CS in coursera[?]\n",
      "What are the top[ research] fields in electrical engineering[?]\n"
     ]
    }
   ],
   "source": [
    "# Dense search results\n",
    "print(\"Dense Search Results:\")\n",
    "results = hybrid_search(query_embeddings, sparse_weight=0.0, dense_weight=1.0)\n",
    "formatted_results = doc_text_formatting(query, results)\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Sparse search results\n",
    "print(\"\\nSparse Search Results:\")\n",
    "results = hybrid_search(query_embeddings, sparse_weight=1.0, dense_weight=0.0)\n",
    "formatted_results = doc_text_formatting(query, results)\n",
    "for result in formatted_results:\n",
    "    print(result)\n",
    "\n",
    "# Hybrid search results\n",
    "print(\"\\nHybrid Search Results:\")\n",
    "results = hybrid_search(query_embeddings, sparse_weight=0.7, dense_weight=1.0)\n",
    "formatted_results = doc_text_formatting(query, results)\n",
    "for result in formatted_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Deploy\n",
    "\n",
    "To learn about how to start an online demo with this tutorial, please refer to [the example application](https://github.com/milvus-io/bootcamp/tree/master/bootcamp/tutorials/quickstart/apps/hybrid_search_with_milvus).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/milvus-io/bootcamp/master/bootcamp/tutorials/quickstart/apps/hybrid_demo_with_milvus/pics/demo.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
