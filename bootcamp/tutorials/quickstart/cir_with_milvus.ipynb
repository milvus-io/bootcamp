{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/cir_with_milvus.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composed Image Retrieval with Milvus üñºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases the integration of Milvus with [MagicLens](https://open-vision-language.github.io/MagicLens/) for advanced image searching based on user instructions. Users can upload an image and provide editing instructions, which are processed by MagicLens's composed retrieval model to search for candidate images. This powerful combination enables a seamless and intuitive image search experience, leveraging Milvus for efficient retrieval and MagicLens for precise image processing and matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pymilvus numpy Pillow opencv-python datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MagicLens Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detailed information can be found at <https://github.com/google-deepmind/magiclens>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the Conda environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create --name magic_lens python=3.9 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Activate the environment and run the subsequent commands manually in a terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate magic_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Clone the repository and navigate to the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/google-research/scenic.git\n",
    "!cd scenic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Install the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install .\n",
    "!pip install -r scenic/projects/baselines/clip/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to install corresponding GPU version of jax following <https://jax.readthedocs.io/en/latest/installation.html>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 12 installation\n",
    "# Note: wheels only available on linux.\n",
    "!pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 11 installation\n",
    "!pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. # in main folder of demo.\n",
    "# you may need to use `gcloud auth login` for access, any gmail account should work.\n",
    "!gsutil cp -R gs://gresearch/magiclens/models ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [categories.txt](https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/apps/cir_with_milvus/categories.txt) file here and keep it in the same directory: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from magiclens.model import MagicLens\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pickle\n",
    "from flax import serialization\n",
    "from scenic.projects.baselines.clip import tokenizer as clip_tokenizer\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"gpu\")\n",
    "\n",
    "\n",
    "def load_model(model_size: str, model_path: str) -> Dict:\n",
    "    \"\"\"Load and initialize the model.\"\"\"\n",
    "    model = MagicLens(model_size)\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    dummy_input = {\n",
    "        \"ids\": jnp.ones((1, 1, 77), dtype=jnp.int32),\n",
    "        \"image\": jnp.ones((1, 224, 224, 3), dtype=jnp.float32),\n",
    "    }\n",
    "    params = model.init(rng, dummy_input)\n",
    "    print(\"Model initialized\")\n",
    "\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model_bytes = pickle.load(f)\n",
    "    params = serialization.from_bytes(params, model_bytes)\n",
    "    print(\"Model loaded\")\n",
    "    return model, params\n",
    "\n",
    "\n",
    "model, model_params = load_model(\n",
    "    \"large\", \"/home/data3/david/magiclens/models/magic_lens_clip_large.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def apply_model(params, image, ids):\n",
    "    return model.apply(params, {\"ids\": ids, \"image\": image})\n",
    "\n",
    "\n",
    "def process_img(image_path: str, size: int) -> np.ndarray:\n",
    "    \"\"\"Process a single image to the desired size and normalize.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((size, size), Image.BILINEAR)\n",
    "    img = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "    img = img[np.newaxis, ...]  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        self.model = model\n",
    "        self.tokenizer = clip_tokenizer.build_tokenizer()\n",
    "        self.model_params = model_params\n",
    "\n",
    "    def encode_query(self, img_path, text):\n",
    "        img = process_img(img_path, 224)\n",
    "        tokens = self.tokenizer(text)\n",
    "        res = apply_model(self.model_params, img, tokens)\n",
    "        return np.array(res[\"multimodal_embed\"])\n",
    "\n",
    "\n",
    "retriever = Retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data and Create Collection\n",
    "\n",
    "We are using a subset of <https://github.com/hyp1231/AmazonReviews2023> which includes approximately 5000 images in 33 different categories, such as applicances, beauty and personal care, clothing, sports and outdoors, etc. <br>\n",
    "Create a collection and load image data from the dataset to get the knowledge ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pymilvus import MilvusClient\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the image folder\n",
    "image_folder = \"/home/data3/david/magiclens/data/images/{}\"\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = Retriever()\n",
    "\n",
    "# Initialize Milvus client\n",
    "client = MilvusClient(\"./milvus_demo.db\")\n",
    "client.create_collection(\n",
    "    collection_name=\"cir_demo_large\",\n",
    "    overwrite=True,\n",
    "    auto_id=True,\n",
    "    dimension=768,\n",
    "    enable_dynamic_field=True,\n",
    ")\n",
    "\n",
    "# Read the categories from the file\n",
    "with open(\"categories.txt\") as fw:\n",
    "    lines = fw.readlines()\n",
    "\n",
    "# Loop through each category, download images, and insert data into Milvus\n",
    "for line in lines:\n",
    "    category = line.strip()\n",
    "    meta_dataset = load_dataset(\n",
    "        \"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_meta_{category}\", split=\"full\"\n",
    "    )\n",
    "\n",
    "    for i in range(100):\n",
    "        if len(meta_dataset[i][\"images\"][\"large\"]) > 0:\n",
    "            img_url = meta_dataset[i][\"images\"][\"large\"][0]\n",
    "            img_name = os.path.basename(img_url)\n",
    "            img_path = image_folder.format(img_name)\n",
    "\n",
    "            # Download the image\n",
    "            os.system(\n",
    "                f\"wget {img_url} -P {os.path.dirname(img_path)} --no-check-certificate\"\n",
    "            )\n",
    "\n",
    "            if os.path.exists(img_path):\n",
    "                # Encode the image\n",
    "                feat = encoder.encode_query(img_path, \"\")\n",
    "                # Create the metadata spec\n",
    "                spec = json.dumps(meta_dataset[i])\n",
    "                # Insert the data into Milvus\n",
    "                res = client.insert(\n",
    "                    collection_name=\"cir_demo_large\",\n",
    "                    data={\n",
    "                        \"vector\": np.array(feat.flatten()),\n",
    "                        \"spec\": spec,\n",
    "                        \"name\": f\"{category}_{i}\",\n",
    "                    },\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Query Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a610727efeba480287f500b767d4aeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157bcd6a4df64dd5a935967a0ccf5adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create an upload widget\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept=\"image/*\",  # Accept only image files\n",
    "    multiple=False,  # Accept only a single file\n",
    ")\n",
    "display(upload_widget)\n",
    "\n",
    "# Create a display output area\n",
    "display_output = widgets.Output()\n",
    "display(display_output)\n",
    "\n",
    "uploaded_image = None\n",
    "\n",
    "\n",
    "def on_upload_change(change):\n",
    "    # Clear previous output\n",
    "    display_output.clear_output()\n",
    "\n",
    "    with display_output:\n",
    "        for uploaded_file in upload_widget.value:\n",
    "            content = uploaded_file[\"content\"]\n",
    "            uploaded_image = Image.open(io.BytesIO(content))\n",
    "            # Display the image\n",
    "            display(uploaded_image)\n",
    "\n",
    "\n",
    "# Attach the handler to the upload widget\n",
    "upload_widget.observe(on_upload_change, names=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Text Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an earphone with the theme of the image\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter your instruction: \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Query and Run the Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = retriever.encode_query(\"temp.jpg\", text)\n",
    "\n",
    "search_results = client.search(\n",
    "    collection_name=\"cir_demo_large\",\n",
    "    data=[emb.flatten()],\n",
    "    output_fields=[\"spec\"],\n",
    "    limit=100,  # Max number of search results to return\n",
    "    search_params={\"metric_type\": \"COSINE\", \"params\": {}},  # Search parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Search Results\n",
    "Top 25 retrieved images will be displayed in the form of a 5x5 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "path = \"/home/data3/david/magiclens/data/images\"\n",
    "for result in search_results:\n",
    "    for hit in result[:25]:\n",
    "        filename = hit[\"entity\"][\"filename\"]\n",
    "        img = Image.open(filename)\n",
    "        img = img.resize((150, 150))\n",
    "        images.append(img)\n",
    "\n",
    "width = 150 * 5\n",
    "height = 150 * 5\n",
    "concatenated_image = Image.new(\"RGB\", (width, height))\n",
    "\n",
    "for idx, img in enumerate(images):\n",
    "    x = idx % 5\n",
    "    y = idx // 5\n",
    "    concatenated_image.paste(img, (x * 150, y * 150))\n",
    "display(\"results\")\n",
    "display(concatenated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Deploy\n",
    "\n",
    "To learn about how to start an online demo with this tutorial, please refer to [the example application](https://github.com/milvus-io/bootcamp/tree/master/bootcamp/tutorials/quickstart/apps/cir_with_milvus).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/milvus-io/bootcamp/master/bootcamp/tutorials/quickstart/apps/cir_with_milvus/pics/cir_demo.jpg\n",
    "\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
