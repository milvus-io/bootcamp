# Build RAG with Milvus

This demo shows you how to build a RAG (Retrieval-Augmented Generation) pipeline with Milvus.<br>

The RAG system combines a retrieval system with a generative model to generate new text based on a given prompt. The system first retrieves relevant documents from a corpus using Milvus, and then uses a generative model to generate new text based on the retrieved documents.

## Code Structure
```text
image_search_with_milvus/
│
├── app.py                  # Main Streamlit application
├── insert.py            # Script to retrieve text data
├── milvus_utils.py         # Milvus-related operations
├── encoder.py              # Text embeddings generation
├── requirements.txt        # List of dependencies
```

- app.py: The main Streamlit application file where the user interface is defined and the RAG chatbot is presented.
- insert.py: This script handles the retrieving text data required for the application and inserting text embeddings into data collection.
- milvus_utils.py: Includes functions for interacting with the Milvus database, such as creating collection and retrieving search results. 
- encoder.py: Converts text input into text embeddings for further use. 

## Quick Deploy

Follow these steps to quickly deploy the application locally:

### Preparation

#### Dependencies and Environment
```sh
pip install -r requirements.txt
```
We will use Azure OpenAI as the LLM in this demo. You should prepare api key `AZURE_OPENAI_API_KEY` and endpoint `AZURE_OPENAI_ENDPOINT` as environment variables.
```sh
os.environ["AZURE_OPENAI_API_KEY"] = "***********"
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://***********"
os.environ["AZURE_DEPLOYMENT"] = "****-***-**-*****"
```

#### Clone the Repository
```sh
git clone <https://github.com/milvus-io/bootcamp.git>
cd bootcamp/bootcamp/tutorials/quickstart/app/rag_search_with_milvus
```

### Dataset Preparation
This chatbot in the demo supports conversation based on knowledge from the Milvus development guide document: <https://raw.githubusercontent.com/milvus-io/milvus/master/DEVELOPMENT.md>. <br>
We will load and create data collection for further processing by running the `insert.py` file.
```sh
python insert.py
```

### Usage
#### Run the Streamlit application
```sh
streamlit run app.py
```
#### Steps:
<div style="text-align: center;">
  <figure>
    <img src="./pics/step1.png" alt="Description of Image" width="700"/>
    <figcaption>Step 1: Enter your question in the chat and click on 'submit' button.</figcaption>
  </figure>
</div>

<div style="text-align: center;">
  <figure>
    <img src="./pics/step2.png" alt="Description of Image" width="700"/>
    <figcaption>Step 2: Response generated by LLM based on the prompt.</figcaption>
  </figure>
</div>

<div style="text-align: center;">
  <figure>
    <img src="./pics/step3.png" alt="Description of Image" width="700"/>
    <figcaption>Step 3: Top 3 retrieved original quotes from text data are listed on the left along with their distances, indicating how related the quote and the prompt are. </figcaption>
  </figure>
</div>