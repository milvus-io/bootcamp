{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/hybrid_serach_with_milvus.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search with Dense and Sparse Vectors in Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate how to conduct hybrid search with [Milvus](https://milvus.io/docs/multi-vector-search.md) and [BGE-M3 model](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3). BGE-M3 model can convert text into dense and sparse vectors. Milvus supports storing both types of vectors in one collection, allowing for hybrid search that enhances the result relevance.\n",
    "\n",
    "Milvus supports Dense, Sparse, and Hybrid retrieval methods:\n",
    "\n",
    "- Dense Retrieval: Utilizes semantic context to understand the meaning behind queries.\n",
    "- Sparse Retrieval: Emphasizes keyword matching to find results based on specific terms, equivalent to full-text search.\n",
    "- Hybrid Retrieval: Combines both Dense and Sparse approaches, capturing the full context and specific keywords for comprehensive search results.\n",
    "\n",
    "By integrating these methods, the Milvus Hybrid Search balances semantic and lexical similarities, improving the overall relevance of search outcomes. This notebook will walk through the process of setting up and using these retrieval strategies, highlighting their effectiveness in various search scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pymilvus \"pymilvus[model]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate search, we need a corpus of documents. Let's use the Quora Duplicate Questions dataset and place it in the local directory. \n",
    "\n",
    "Source of the dataset: [First Quora Dataset Release: Question Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download the dataset\n",
    "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data\n",
    "\n",
    "We will load the dataset and prepare a small corpus for search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happened to Luna Lovegood after Book 7?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"quora_duplicate_questions.tsv\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "questions = set()\n",
    "for _, row in df.iterrows():\n",
    "    obj = row.to_dict()\n",
    "    questions.add(obj[\"question1\"][:512])\n",
    "    questions.add(obj[\"question2\"][:512])\n",
    "    if len(questions) > 10000:\n",
    "        break\n",
    "\n",
    "docs = list(questions)\n",
    "\n",
    "# example question\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BGE-M3 Model for Embeddings\n",
    "\n",
    "The BGE-M3 model can embed texts as dense and sparse vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 302473.85it/s]\n",
      "Inference Embeddings: 100%|██████████| 626/626 [04:39<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from milvus_model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")\n",
    "dense_dim = ef.dim[\"dense\"]\n",
    "\n",
    "# Generate embeddings using BGE-M3 model\n",
    "docs_embeddings = ef(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Random Embeddings (Optional)\n",
    "\n",
    "If you do not have the BGE-M3 model, you can generate random embeddings for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def random_embedding(texts):\n",
    "    rng = np.random.default_rng()\n",
    "    return {\n",
    "        \"dense\": np.random.rand(len(texts), 768),\n",
    "        \"sparse\": [\n",
    "            {\n",
    "                d: rng.random()\n",
    "                for d in random.sample(range(1000), random.randint(20, 30))\n",
    "            }\n",
    "            for _ in texts\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "dense_dim = 768\n",
    "ef = random_embedding\n",
    "docs_embeddings = ef(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Milvus Collection and Index\n",
    "\n",
    "We will now set up the Milvus collection and create indices for the vector fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    connections,\n",
    ")\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(\"default\", uri=\"milvus.db\")\n",
    "\n",
    "# Specify the data schema for the new Collection\n",
    "fields = [\n",
    "    # Use auto generated id as primary key\n",
    "    FieldSchema(\n",
    "        name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n",
    "    ),\n",
    "    # Store the original text to retrieve based on semantically distance\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512),\n",
    "    # Milvus now supports both sparse and dense vectors,\n",
    "    # we can store each in a separate field to conduct hybrid search on both vectors\n",
    "    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "]\n",
    "schema = CollectionSchema(fields, \"\")\n",
    "col_name = \"hybrid_demo\"\n",
    "col = Collection(col_name, schema, consistency_level=\"Strong\")\n",
    "\n",
    "# To make vector search efficient, we need to create indices for the vector fields\n",
    "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "col.create_index(\"sparse_vector\", sparse_index)\n",
    "dense_index = {\"index_type\": \"FLAT\", \"metric_type\": \"IP\"}\n",
    "col.create_index(\"dense_vector\", dense_index)\n",
    "col.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "# Connect to Milvus\n",
    "client = MilvusClient(uri=\"./milvus_demo.db\")\n",
    "\n",
    "# Specify the data schema for the new Collection\n",
    "schema = MilvusClient.create_schema(\n",
    "    auto_id=True,  # Auto-generated id\n",
    "    enable_dynamic_field=True,\n",
    ")\n",
    "\n",
    "# Add fields to the schemax\n",
    "schema.add_field(\n",
    "    field_name=\"pk\", datatype=DataType.VARCHAR, is_primary=True, max_length=100\n",
    ")\n",
    "schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=512)\n",
    "schema.add_field(field_name=\"sparse_vector\", datatype=DataType.SPARSE_FLOAT_VECTOR)\n",
    "schema.add_field(\n",
    "    field_name=\"dense_vector\", datatype=DataType.FLOAT_VECTOR, dim=128\n",
    ")  # assuming dense_dim is 128\n",
    "\n",
    "# Create the collection with the specified schema\n",
    "collection_name = \"hybrid_demo\"\n",
    "client.create_collection(collection_name=collection_name, schema=schema)\n",
    "\n",
    "index_params = MilvusClient.prepare_index_params()\n",
    "\n",
    "# Create index for the sparse vector\n",
    "index_params.add_index(\n",
    "    field_name=\"sparse_vector\",\n",
    "    metric_type=\"IP\",\n",
    "    index_type=\"SPARSE_INVERTED_INDEX\",\n",
    ")\n",
    "\n",
    "# Create index for the dense vector\n",
    "index_params.add_index(\n",
    "    field_name=\"dense_vector\",\n",
    "    metric_type=\"IP\",\n",
    "    index_type=\"FLAT\",\n",
    ")\n",
    "\n",
    "client.create_index(\n",
    "    collection_name=collection_name,\n",
    "    index_params=index_params,\n",
    ")\n",
    "\n",
    "# Load the collection\n",
    "client.load_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Data into Milvus Collection\n",
    "Insert the text and sparse/dense vector representations into the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert documents and their embeddings into the collection.\n",
    "# For efficiency, we insert 50 records in each small batch\n",
    "entities = [docs, docs_embeddings[\"sparse\"], docs_embeddings[\"dense\"]]\n",
    "for i in range(0, len(docs), 50):\n",
    "    batched_entities = [\n",
    "        docs[i : i + 50],\n",
    "        docs_embeddings[\"sparse\"][i : i + 50],\n",
    "        docs_embeddings[\"dense\"][i : i + 50],\n",
    "    ]\n",
    "    col.insert(batched_entities)\n",
    "col.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter Your Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who started AI research?\n",
      "{'dense': [array([-0.03658685, -0.01750261, -0.01536112, ..., -0.02266536,\n",
      "        0.01365146,  0.00908284], dtype=float32)], 'sparse': <1x250002 sparse array of type '<class 'numpy.float32'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>}\n"
     ]
    }
   ],
   "source": [
    "# Enter your search query\n",
    "query = input(\"Enter your search query: \")\n",
    "print(query)\n",
    "\n",
    "# Generate embeddings for the query\n",
    "query_embeddings = ef([query])\n",
    "print(query_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    AnnSearchRequest,\n",
    "    WeightedRanker,\n",
    ")\n",
    "\n",
    "\n",
    "def get_collection():\n",
    "    col_name = \"hybrid_demo\"\n",
    "    connections.connect(\"default\", uri=\"milvus.db\")\n",
    "    col = Collection(col_name)\n",
    "    return col\n",
    "\n",
    "\n",
    "def hybrid_search(query_embeddings, sparse_weight=1.0, dense_weight=1.0):\n",
    "    col = get_collection()\n",
    "    sparse_search_params = {\"metric_type\": \"IP\"}\n",
    "    sparse_req = AnnSearchRequest(\n",
    "        query_embeddings[\"sparse\"], \"sparse_vector\", sparse_search_params, limit=10\n",
    "    )\n",
    "    dense_search_params = {\"metric_type\": \"IP\"}\n",
    "    dense_req = AnnSearchRequest(\n",
    "        query_embeddings[\"dense\"], \"dense_vector\", dense_search_params, limit=10\n",
    "    )\n",
    "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "    res = col.hybrid_search(\n",
    "        [sparse_req, dense_req], rerank=rerank, limit=10, output_fields=[\"text\"]\n",
    "    )\n",
    "    if len(res):\n",
    "        return [hit.fields[\"text\"] for hit in res[0]]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results = hybrid_search(query_embeddings, sparse_weight=0.0, dense_weight=1.0)\n",
    "sparse_results = hybrid_search(query_embeddings, sparse_weight=1.0, dense_weight=0.0)\n",
    "hybrid_results = hybrid_search(query_embeddings, sparse_weight=0.7, dense_weight=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Search Results\n",
    "\n",
    "Display the results for Dense, Sparse, and Hybrid methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer():\n",
    "    tokenizer = ef.model.tokenizer\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def doc_text_formatting(query, docs):\n",
    "    tokenizer = get_tokenizer()\n",
    "    query_tokens_ids = tokenizer.encode(query, return_offsets_mapping=True)\n",
    "    query_tokens = tokenizer.convert_ids_to_tokens(query_tokens_ids)\n",
    "    formatted_texts = []\n",
    "\n",
    "    for doc in docs:\n",
    "        ldx = 0\n",
    "        landmarks = []\n",
    "        encoding = tokenizer.encode_plus(doc, return_offsets_mapping=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])[1:-1]\n",
    "        offsets = encoding[\"offset_mapping\"][1:-1]\n",
    "        for token, (start, end) in zip(tokens, offsets):\n",
    "            if token in query_tokens:\n",
    "                if len(landmarks) != 0 and start == landmarks[-1]:\n",
    "                    landmarks[-1] = end\n",
    "                else:\n",
    "                    landmarks.append(start)\n",
    "                    landmarks.append(end)\n",
    "        close = False\n",
    "        formatted_text = \"\"\n",
    "        for i, c in enumerate(doc):\n",
    "            if ldx == len(landmarks):\n",
    "                pass\n",
    "            elif i == landmarks[ldx]:\n",
    "                if close is True:\n",
    "                    formatted_text += \"]\"\n",
    "                else:\n",
    "                    formatted_text += \"[\"\n",
    "                close = not close\n",
    "                ldx = ldx + 1\n",
    "            formatted_text += c\n",
    "        if close is True:\n",
    "            formatted_text += \"]\"\n",
    "        formatted_texts.append(formatted_text)\n",
    "    return formatted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Search Results:\n",
      "What's the best way to start learning robotics?\n",
      "When in history did we start giving people names?\n",
      "Why did humans come into existence?\n",
      "Who invented thermometer?\n",
      "Should a machine learning beginner go straight for deep learning?\n",
      "How do I start learning or strengthen my knowledge of data structures and algorithms?\n",
      "How can undergraduate help with machine learning research?\n",
      "Why do so many people believe that the IQ test determines your intelligence?\n",
      "Why is the term \"research\" used instead of scientific investigation?\n",
      "Do humans fear artificial intelligence because it has no soul?\n",
      "How do I research for MUN?\n",
      "What is subjectivity and objectivity in research?\n",
      "What are the top research fields in electrical engineering?\n",
      "What is the best way to do an MUN research?\n",
      "What advice will you give to an IIT graduate in Mechanical/Civil Engineering, who strongly wants to pursue a research career in computer science/mathematics, and has completed the basic courses of CS in coursera?\n",
      "What is research objective?\n",
      "What topic should I research for my EPQ project?\n",
      "How do I get help for research paper?\n",
      "How could neutrinos be used for scientific research?\n",
      "\n",
      "Sparse Search Results:\n",
      "What is[ research] objective[?]\n",
      "How do I[ research] for MUN[?]\n",
      "What is the best way to do an MUN[ research?]\n",
      "What is subjectivity and objectivity in[ research?]\n",
      "What topic should I[ research] for my EPQ project[?]\n",
      "How could neutrinos be used for scientific[ research?]\n",
      "How do I get help for[ research] paper[?]\n",
      "What advice will you give to an IIT graduate in Mechanical/Civil Engineering, who strongly wants to pursue a[ research] career in computer science/mathematics, and has completed the basic courses of CS in coursera[?]\n",
      "What are the top[ research] fields in electrical engineering[?]\n",
      "How can undergraduate help with machine learning[ research?]\n",
      "Should a machine learning beginner go straight for deep learning[?]\n",
      "Why do so many people believe that the IQ test determines your intelligence[?]\n",
      "When in history did we start giving people names[?]\n",
      "What's the best way to start learning robotics[?]\n",
      "Why is the term \"research\" used instead of scientific investigation[?]\n",
      "[Who] invented thermometer[?]\n",
      "Do humans fear artificial intelligence because it has no soul[?]\n",
      "How do I start learning or strengthen my knowledge of data structures and algorithms[?]\n",
      "Why did humans come into existence[?]\n",
      "\n",
      "Hybrid Search Results:\n",
      "How can undergraduate help with machine learning[ research?]\n",
      "What's the best way to start learning robotics[?]\n",
      "When in history did we start giving people names[?]\n",
      "Why did humans come into existence[?]\n",
      "[Who] invented thermometer[?]\n",
      "Should a machine learning beginner go straight for deep learning[?]\n",
      "How do I start learning or strengthen my knowledge of data structures and algorithms[?]\n",
      "Why do so many people believe that the IQ test determines your intelligence[?]\n",
      "Why is the term \"research\" used instead of scientific investigation[?]\n",
      "Do humans fear artificial intelligence because it has no soul[?]\n",
      "What is[ research] objective[?]\n",
      "How do I[ research] for MUN[?]\n",
      "What is the best way to do an MUN[ research?]\n",
      "What is subjectivity and objectivity in[ research?]\n",
      "What topic should I[ research] for my EPQ project[?]\n",
      "How could neutrinos be used for scientific[ research?]\n",
      "How do I get help for[ research] paper[?]\n",
      "What advice will you give to an IIT graduate in Mechanical/Civil Engineering, who strongly wants to pursue a[ research] career in computer science/mathematics, and has completed the basic courses of CS in coursera[?]\n",
      "What are the top[ research] fields in electrical engineering[?]\n"
     ]
    }
   ],
   "source": [
    "# Dense search results\n",
    "print(\"Dense Search Results:\")\n",
    "formatted_results = doc_text_formatting(query, dense_results)\n",
    "for result in dense_results:\n",
    "    print(result)\n",
    "\n",
    "# Sparse search results\n",
    "print(\"\\nSparse Search Results:\")\n",
    "formatted_results = doc_text_formatting(query, sparse_results)\n",
    "for result in formatted_results:\n",
    "    print(result)\n",
    "\n",
    "# Hybrid search results\n",
    "print(\"\\nHybrid Search Results:\")\n",
    "formatted_results = doc_text_formatting(query, hybrid_results)\n",
    "for result in formatted_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Deploy\n",
    "\n",
    "To learn about how to start an online demo with this tutorial, please refer to [the example application](https://github.com/milvus-io/bootcamp/tree/master/bootcamp/tutorials/quickstart/apps/hybrid_demo_with_milvus).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/milvus-io/bootcamp/master/bootcamp/tutorials/quickstart/apps/hybrid_demo_with_milvus/pics/demo.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
